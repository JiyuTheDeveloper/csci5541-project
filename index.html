<!DOCTYPE html>
<html lang="en-US">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NLP Class Project | Spring 2025 CSCI 5541 | University of Minnesota</title>

  <link rel="stylesheet" href="./files/bulma.min.css">
  <link rel="stylesheet" href="./files/styles.css">
  <link rel="preconnect" href="https://fonts.gstatic.com/">
  <link href="./files/css2" rel="stylesheet">
  <link href="./files/css" rel="stylesheet">

  <style>
    /* Apply Lato font to the entire page */
    body {
      font-family: 'Lato', sans-serif;
    }

    /* Optional: You can further customize if needed */
    h1, h4 {
      font-family: 'Lato', sans-serif;
    }

    .wrapper {
      font-family: 'Lato', sans-serif;
    }
  </style>

  <base href="." target="_blank">
</head>

<body>
  <div>
    <div class="wrapper">
      <h1>Using Sentiment Analysis to Measure Perception of Mental Health Across Different Platforms</h1>
      <h4>Fall 2025 CSCI 5541 NLP: Class Project - University of Minnesota</h4>
      <h4>Golden Data Retrievers</h4>

      <div class="authors-wrapper">
        <div class="author-container">

          <p>Jiyu Huang</p>
        </div>

        <div class="author-container">

          <p>Ziqi Zhou</p>
        </div>

        <div class="author-container">

          <p>Kylie Dyke</p>
        </div>
      </div>

      <br/>

      <div class="authors-wrapper">
        <div class="publication-links">
          <span class="link-block">
            <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark is-outlined">
              <span>Final Report</span>
            </a>
          </span>
          <span class="link-block">
            <a href="https://github.com/JiyuTheDeveloper/csci5541-project/tree/main" target="_blank" class="external-link button is-normal is-rounded is-dark is-outlined">
              <span>Code</span>
            </a>
          </span>
          <span class="link-block">
            <a href="" target="_blank" class="external-link button is-normal is-rounded is-dark is-outlined">
              <span>Datasets</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>

  <div class="wrapper">
    <hr>
    <h2 id="abstract">Abstract</h2>
    <p>
      Large‑scale sentiment studies of Reddit's mental‑health communities require reliable knowledge of who is speaking, yet demographic cues such as gender, race, and queer identity are rarely explicit and have traditionally been identified by slow, manual coding. We introduce a two‑stage pipeline that first filters posts with carefully designed keyword lists and then replaces manual labeling with a lightweight, multi‑label DistilBERT classifier. Trained on a gold‑standard set of 1,782 hand‑annotated posts, the model accurately predicts four binary attributes—mental‑health mention, gender identity, racial identity, and queer identity—allowing us to automate what was previously weeks of expert effort. The resulting, fully labeled corpus reveals that sentiment on mental‑health subreddits differs markedly across social identities; for example, posts authored by queer‑identified users are consistently more negative than those without queer markers, and male-identified posts show slightly more positive sentiment than female-identified ones. By removing the annotation bottleneck, our approach enables far larger, demographically informed analyses of online mental‑health discourse.
    </p>

    <hr>
    <h2 id="introduction">Motivation</h2>
    <p>
      Our ultimate goal was to develop a mental health-focused dataset, establish a robust annotation framework, and then analyze the differences between subpopulations. We then explored how to create an automated classifier that can predict the presence of these demographic tags to streamline annotation for demographic information in social media posts in future work, saving both time and effort.
      Current sentiment analysis approaches often apply a generalized perspective without considering demographic factors, limiting our understanding of unique challenges faced by different groups.</strong>
    </p>

    <p>
      Right now, researchers use social media data to study mental health, but most of this data is anonymous and lacks demographic information. This means we miss how specific groups feel or struggle differently, and we can’t spot patterns tied to identity.
      If we’re successful, this will help mental health researchers and advocates better understand the needs of underrepresented groups. It could lead to more targeted support, outreach, and resources for communities that are often overlooked.
    </p>

    <hr>
    <h2 id="introduction">Scientific Novelty</h2>
    <p>
      <ol>
        <li>
          <strong>Demographic-enriched sentiment analysis</strong> – Unlike most mental health sentiment analyses that treat users as a homogeneous group (e.g., Benrouba and Boudour's 2023 work <a href="#benrouba2023">[1]</a> which analyzes emotional sentiment for mental health safety without demographic considerations), our work specifically examines how sentiment varies across social identities. While Rai et al. (2024) <a href="#rai2024">[2]</a> explored cross-cultural differences in mental health expressions, they focused only on geographic/national identity rather than personal demographic characteristics like gender or LGBTQ+ status.
        </li>
        <li>
          <strong>Automated demographic inference</strong> – We developed a multi-label model that can simultaneously predict four demographic and mental health attributes from text alone, addressing a major bottleneck in demographic analysis of anonymous content. Prior approaches like those used by Park et al. (2018) <a href="#park2018">[3]</a> either ignored demographic factors entirely or relied on manual annotation processes that couldn't scale. Our system's micro-accuracy of 78.7% demonstrates significant improvement over keyword-based approaches that fail to capture contextual cues.
        </li>
        <li>
          <strong>Two-stage pipeline approach</strong> – Our methodology uniquely combines keyword filtering with transformer-based multi-label classification. This contrasts with Rani et al.'s (2024) <a href="#rani2024">[4]</a> approach to mental health dataset annotation, which relied on a single-stage expert labeling process without automated classification. Their method requires weeks of expert effort for each new dataset, while our pipeline can process thousands of posts automatically once trained.
        </li>
        <li>
          <strong>Scalable annotation pipeline</strong> – We developed a structured annotation protocol specifically for demographic inference from anonymous posts, which distinguishes our work from Liu et al. (2022) <a href="#liu2022">[5]</a>, who focused on depression detection without accounting for demographic variation. Their supervised learning approaches targeted mental health conditions directly rather than building demographic context for more nuanced analysis.
        </li>
        <li>
          <strong>Interdisciplinary integration</strong> – Our methodology bridges computational linguistics, mental health informatics, and social identity research in a way that enables broader insights into online mental health discourse. Prior work by Le Glaz et al. (2021) <a href="#leglaz2021">[6]</a> identified the lack of interdisciplinary approaches as a significant limitation in mental health NLP research. Our work directly addresses this gap.
        </li>
      </ol>
      
    </p>
    <hr>
    
    <h2 id="approach">Data Curation</h2>
    <p>
      We collected Reddit posts related to mental health, specifically from the Reddit Mental Health Dataset (RMHD) on Kaggle. These posts were specifically from the months of August to November of 2019. We wanted to avoid any bias or impact from the COVID-19 pandemic, so we utilized the months prior to major worldwide impacts. We did not previously consider how the United States presidential election could have affected this when we chose these months; however, there was no mention explicitly regarding the election.
    </p>

    <p>
      These posts were then flagged by an R script with key words for each identity. After flagging, each member of our team worked on manually annotating the self_text (post) with multiple demographic labels. These demographic labels include the mental health of the writer of the post and the earlier defined vulnerable populations: gender identity, LGBTQ+ identity, and race identity. This includes marking a binary indicator, details from a predefined list (that was adjusted as needed), and comments for follow-up or to explain why a flagged term did not result in inclusion.
    </p>

    <p>After reading a post, the annotator fills in the following columns:</p>

    <ul>
      <li><strong>Mental health Related:</strong>
        <ul style="list-style-type: disc; margin-left: 20px;">
          <li>label_mental_health (binary)</li>
          <li>disorder (list options)</li>
          <li>diagnosed (binary)</li>
          <li>SeekingHelp_copingMechanisms (binary)</li>
          <li>details (free text)</li>
        </ul>
      </li>

      <li><strong>Gender Identity Related:</strong>
        <ul style="list-style-type: disc; margin-left: 20px;">
          <li>label_Gender_Identity (binary)</li>
          <li>Gender_Identity (list options)</li>
          <li>Details (free text)</li>
        </ul>
      </li>

      <li><strong>Race Identity Related:</strong>
        <ul style="list-style-type: disc; margin-left: 20px;">
          <li>label_racial_identity (binary)</li>
          <li>race_identity (list options)</li>
          <li>race_identity_specific (free text)</li>
        </ul>
      </li>

      <li><strong>Queer Identity Related:</strong>
        <ul style="list-style-type: disc; margin-left: 20px;">
          <li>label_queer_identity (binary)</li>
          <li>queer_identity (list options)</li>
          <li>extra_comments (free text)</li>
        </ul>
      </li>
    </ul>

    <p>If there was any doubt regarding classification, the annotator would reach out to fellow annotators for ruling.</p>

    <hr>
    
    <h2 id="approach">Challenges</h2>
<ul style="list-style-type: disc; margin-left: 20px;">
  <li>
    Annotation
    <ul style="list-style-type: circle; margin-left: 20px;">
      <li>
        Annotating demographic information presented multiple challenges:
        <ul style="list-style-type: square; margin-left: 20px;">
          
          <li>  
            <strong> Time Consuming </strong> -  Annotating the data was a lot more time-consuming and mentally draining than anticipated. Our rigorous labeling of the posts meant we spent more time on each post than anticipated, especially if the posts were long (approaching our 3000 character maximum), confusing, or required an extra check by another annotator. Since we knew that annotation would need to be systematic to keep the differences between annotators low, we applied a trial and error where we would label the first 30 or so samples across our datasets (since we split them by presence or absence of flags). This allowed us to have a key idea of how annotation would go for the remainder of our samples.
          </li>
          
          <li>
            <strong>Imbalanced label distribution</strong> – Demographic information was unevenly represented, with racial identity present in only ~5% of posts and gender in ~16%. To address this, we carefully evaluated performance metrics that account for class imbalance (macro-F1) and implemented balanced sampling during training.
          </li>
          <li>
            <strong>Inference complexity</strong> – Determining demographic information from text required careful consideration of contextual clues. Our annotation framework needed to distinguish between mentions of others versus self-identification. We refined our guidelines through iterative testing on sample posts.
          </li>
          <li>
            <strong>Ambiguous identity expressions</strong> – Users expressed identities in various ways, sometimes using slang or community-specific terminology. Our approach incorporated an expansive dictionary of identity terms and manual verification during the gold-standard dataset creation.
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    Ethics
    <ul style="list-style-type: circle; margin-left: 20px;">
      <li>
        <strong>Ethical considerations</strong> – We recognized the sensitivity of inferring identity characteristics. Our binary classification approach (presence/absence of identity markers) aimed to minimize assumptions while still capturing relevant patterns.
      </li>
    </ul>
  </li>
</ul>

    <hr>

    <h2 id="teaser">Annotation Workflow</h2>
    <p class="sys-img"><img src="./files/Annotation_workflow.png" alt="imgname" width="800"></p>

    <h3 id="teaser">Current Demographics</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Annotation_Demographic.png">
    </div>

    <hr>
    <h1 id="Models">Models</h1>
    <h2 id="Models">Model 1: Vader Sentiment</h2>
      <p>VADER (Valence Aware Dictionary and Sentiment Reasoner) is a lexicon and rule-based sentiment analysis tool specifically designed for social media content. We saw it perform with more variety for the Reddit posts compared ot DistilBERT. </p>
    <h3 id="Models">Model 1: Gender Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_gender_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_gender_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_gender_significance_tests.png">
    </div>

    <h3 id="Models">Model 1: Queer Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_SUB_queer_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_SUB_queer_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_SUB_queer_significance_tests.png">
    </div>

    <h3 id="Models">Model 1: Race Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_race_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_racial_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/VADER_racial_significance_tests.png">
    </div>

    <h2 id="Models">Model 2: DistilBERT</h2>
      <p>DistilBERT is a lighter transformer-based model pre-trained for sentiment classification. </p>
    <h3 id="Models">Model 2: Gender Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_gender_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_gender_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_gender_significance_tests.png">
    </div>

    <h3 id="Models">Model 2: Queer Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_SUB_queer_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_SUB_queer_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/Graphs/BERT_SUB_queer_significance_tests.png">
    </div>

    <h3 id="Models">Model 2: Race Identity</h3>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_race_sentiment_distribution.png">
    </div>
    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_racial_sentiment_heatmap.png">
    </div>

    <div style="text-align: center;">
      <img style="height: 300px;" alt="" src="./files/Graphs/BERT_racial_significance_tests.png">
    </div>

    <hr>
    <h2 id="Evaluation">Demographic Model Evaluation</h2>

    
    <h2 id="Evaluation">Classification Model Evaluation</h2>
    <table>
      <tr>
        <th>Metric</th>
        <th>Value</th>
      </tr>
      <tr>
        <td>Macro-F1</td>
        <td>0.500</td>
      </tr>
      <tr>
        <td>Micro-F1</td>
        <td>0.787</td>
      </tr>
      <tr>
        <td>Micro-Accuracy</td>
        <td>0.877</td>
      </tr>
      <tr>
        <td>Subset Accuracy</td>
        <td>0.593</td>
      </tr>
    </table>
    
    <p>Micro-accuracy reports the proportion of correctly predicted labels. Micro-F1 is the average F1 score calculated globally by counting total true positives, false negatives, and flase positives across all labels. It is best when class imbalances exist. Macro-F1 is the average F1 score across classes, giving equal weight to each class. Subset-accuracy was how accurate a proportion of samples where all labels are correctly predicted</p>

    <hr>
    <h1 id="Conclusion">Conclusion</h1>

    <p>
      Our project demonstrates that sentiment toward mental health differs significantly across demographic groups in online discussions. By developing an effective multi-label classifier for demographic information, we've created a scalable approach to analyze these differences in large datasets of anonymous content.
      The observed patterns—including more negative sentiment among female and transgender users and more positive sentiment among male and Hispanic users—point to important variations in how different groups express and discuss mental health. These differences align with real-world disparities documented in recent research. The Trevor Project (2023) found that 41\% of LGBTQ+ youth had seriously considered suicide \cite{trevor2023}, highlighting the mental health challenges faced by these communities. Similarly, Olfson et al. (2023) documented substantial disparities in mental health care access across racial-ethnic groups \cite{olfson2023}, which may influence how different communities discuss mental health online.
      By enabling demographic-aware analysis of mental health content, our work supports more nuanced understanding of how identity shapes mental health experiences and expressions. This approach has significant potential to inform more tailored, culturally sensitive mental health interventions and support resources for diverse populations. Given that 23.1\% of US adults experience mental illness \cite{nimh2023}, but treatment patterns vary dramatically by demographic factors \cite{olfson2023}, tools that help understand these patterns are increasingly important.
      Our methodology also represents an important advance in computational approaches to demographic inference from anonymous content, with potential applications beyond mental health to other domains where understanding demographic patterns is important but demographic data is not explicitly available.
    </p>

    <h2>Next Steps</h2>
    <p>Moving foward, it would be best to annotate more posts to try to even out the imbalance and work on a model that can classify by more downstream labels. We would also like to then test our classifier on other social media platform hosts. If this classifier can become accurate enough it will be a tool that can be used by many to survey the current attitutde towards mental health in different communities.</p>
  </div>

<h2 id="references">References</h2>
<ol>
  <li id="liu2022">
    Liu, D., Feng, X. L., Ahmed, F., Shahid, M., & Guo, J. (2022). 
    Detecting and Measuring Depression on Social Media Using a Machine Learning Approach: Systematic Review. 
    <em>JMIR Mental Health</em>, <strong>9</strong>(3), e27244.
  </li>
  <li id="park2018">
    Park, A., Conway, M., & Chen, A. T. (2018). 
    Examining thematic similarity, difference, and membership in three online mental health communities from Reddit: A text mining and visualization approach. 
    <em>Computers in Human Behavior</em>, <strong>78</strong>, 98–112.
  </li>
  <li id="rai2024">
    Rai, S., Shelat, K., Jain, D. R., Sivabalan, K., Cho, Y. M., Redkar, M., Sawant, S., Ungar, L. H., & Guntuku, S. C. (2024). 
    Cross-Cultural Differences in Mental Health Expressions on Social Media.
  </li>
  <li id="reece2017">
    Reece, A. G., Reagan, A. J., Lix, K. L. M., Dodds, P. S., Danforth, C. M., & Langer, E. J. (2017). 
    Forecasting the onset and course of mental illness with Twitter data. 
    <em>Scientific Reports</em>, <strong>7</strong>(1), 13006.
  </li>
  <li id="zhang2022">
    Zhang, T., Schoene, A. M., Ji, S., et al. (2022). 
    Natural language processing applied to mental illness detection: a narrative review. 
    <em>npj Digital Medicine</em>, <strong>5</strong>, 46.
  </li>
  <li id="benrouba2023">
    Benrouba, F., & Boudour, R. (2023). 
    Emotional sentiment analysis of social media content for mental health safety. 
    <em>Social Network Analysis and Mining</em>, <strong>13</strong>(1), 17.
  </li>
  <li id="leglaz2021">
    Le Glaz, A., Haralambous, Y., Kim-Dufor, D. H., Lenca, P., Billot, R., Ryan, T. C., Marsh, J., DeVylder, J., Walter, M., Berrouiguet, S., & Lemey, C. (2021). 
    Machine Learning and Natural Language Processing in Mental Health: Systematic Review. 
    <em>Journal of Medical Internet Research</em>, <strong>23</strong>(5), e15708.
  </li>
  <li id="rani2024">
    Rani, S., Ahmed, K., & Subramani, S. (2024). 
    From Posts to Knowledge: Annotating a Pandemic-Era Reddit Dataset to Navigate Mental Health Narratives. 
    <em>Applied Sciences</em>, <strong>14</strong>, 1547.
  </li>
  <li id="trevor2023">
    The Trevor Project. (2023). 
    <em>2023 National Survey on LGBTQ Youth Mental Health</em>. The Trevor Project.
  </li>
  <li id="nimh2023">
    National Institute of Mental Health. (2023). 
    <em>Mental Illness</em>. National Institute of Health.
  </li>
  <li id="olfson2023">
    Olfson, M., Zuvekas, S. H., McClellan, C., Wall, M. M., Hankerson, S. H., & Blanco, C. (2023). 
    Racial-Ethnic Disparities in Outpatient Mental Health Care in the United States. 
    <em>Psychiatric Services</em>, <strong>74</strong>(7), 674–683.
  </li>
</ol>


</body>
</html>
